{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas pillow tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2  \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_path = \"/kaggle/input/moddelite/ModdeDataset\"  # Original dataset\n",
    "jpeg_dataset_path = \"/kaggle/working/MODDE_JPEG\"  # Path for converted JPEG images\n",
    "\n",
    "# Step 1: Convert images to JPEG format\n",
    "def convert_images_to_jpeg(src_dir, dest_dir):\n",
    "    \"\"\" Converts all images in src_dir to JPEG format and saves them in dest_dir. \"\"\"\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "\n",
    "    for root, _, files in os.walk(src_dir):\n",
    "        for file in files:\n",
    "            src_file_path = os.path.join(root, file)  \n",
    "            rel_path = os.path.relpath(root, src_dir)  \n",
    "            dest_dir_path = os.path.join(dest_dir, rel_path)  \n",
    "            dest_file_path = os.path.join(dest_dir_path, file)  \n",
    "\n",
    "            if not os.path.exists(dest_dir_path):\n",
    "                os.makedirs(dest_dir_path)\n",
    "\n",
    "            # Skip files that already exist\n",
    "            if os.path.exists(dest_file_path):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Convert to RGB JPEG format\n",
    "                with Image.open(src_file_path) as img:\n",
    "                    if img.mode != 'RGB':  \n",
    "                        img = img.convert('RGB')\n",
    "                    dest_file_path = os.path.splitext(dest_file_path)[0] + '.jpg'\n",
    "                    img.save(dest_file_path, 'JPEG')\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {src_file_path}: {e}\")\n",
    "\n",
    "# Run conversion\n",
    "convert_images_to_jpeg(dataset_path, jpeg_dataset_path)\n",
    "\n",
    "# Step 2: Load dataset with preprocessing\n",
    "def preprocess_image(image, label):\n",
    "    \"\"\" Preprocesses the image: resize, normalize, and apply data augmentation. \"\"\"\n",
    "    # Resize to (256, 256)\n",
    "    image = tf.image.resize(image, (256, 256))  \n",
    "\n",
    "    # Normalize pixel values to [0,1]\n",
    "    image = image / 255.0  \n",
    "\n",
    "    # Data augmentation\n",
    "    image = tf.image.random_flip_left_right(image)  # Random horizontal flip\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)  # Adjust brightness\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)  # Adjust contrast\n",
    "\n",
    "    return image, label\n",
    "\n",
    "# Load dataset\n",
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    jpeg_dataset_path,\n",
    "    labels='inferred',  \n",
    "    label_mode='categorical',  \n",
    "    batch_size=32,  \n",
    "    image_size=(256, 256),  \n",
    "    shuffle=True,  \n",
    "    seed=123  \n",
    ")\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "data = data.map(preprocess_image)\n",
    "\n",
    "# Step 3: Display sample images\n",
    "plt.figure(figsize=(12, 8))\n",
    "shown_classes = set()\n",
    "grid_size = (3, 4)  \n",
    "\n",
    "for images, labels in data.take(1):\n",
    "    for i in range(len(images)):\n",
    "        label_index = np.argmax(labels[i].numpy())  \n",
    "        if label_index not in shown_classes:\n",
    "            ax = plt.subplot(grid_size[0], grid_size[1], len(shown_classes) + 1)  \n",
    "            ax.imshow(images[i].numpy())\n",
    "            ax.set_title(data.class_names[label_index], fontsize=12, weight=\"bold\", color=\"#333333\")\n",
    "            ax.axis(\"off\")\n",
    "            shown_classes.add(label_index)\n",
    "        if len(shown_classes) == len(data.class_names):  \n",
    "            break\n",
    "    if len(shown_classes) == len(data.class_names):  \n",
    "        break\n",
    "\n",
    "plt.suptitle(\"Sample Images after Preprocessing\", fontsize=16, weight=\"bold\", color=\"#222222\", y=0.92)\n",
    "plt.tight_layout(pad=2.0, rect=[0, 0, 1, 0.92])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load pre-trained MobileNetV2 model\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(image_path):\n",
    "    img = load_and_preprocess_image(image_path)  # Load image\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    img = preprocess_input(img)  # Apply model-specific preprocessing\n",
    "    features = feature_extractor.predict(img)  # Extract features\n",
    "    return features.flatten()  # Flatten to 1D vector\n",
    "\n",
    "# Extract features for all images in our dataset\n",
    "image_features = np.array([extract_features(img) for img in image_files])\n",
    "\n",
    "print(f\"Extracted feature shape: {image_features.shape}\")  # Should be (num_images, 1280)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Get feature vector dimensions\n",
    "feature_dim = image_features.shape[1]\n",
    "\n",
    "# Create FAISS index\n",
    "index = faiss.IndexFlatL2(feature_dim)  # L2 (Euclidean) distance\n",
    "index.add(image_features)  # Add feature vectors to the index\n",
    "\n",
    "print(f\"Stored {index.ntotal} images in FAISS index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_images(query_image_path, top_k=3):\n",
    "    query_features = extract_features(query_image_path)  # Extract features\n",
    "    query_features = np.expand_dims(query_features, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Search in FAISS index\n",
    "    distances, indices = index.search(query_features, top_k)\n",
    "\n",
    "    # Display results\n",
    "    fig, axes = plt.subplots(1, top_k + 1, figsize=(15, 5))\n",
    "\n",
    "    # Show query image\n",
    "    axes[0].imshow(load_and_preprocess_image(query_image_path))\n",
    "    axes[0].set_title(\"Query Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    # Show retrieved images\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        img_path = image_files[idx]\n",
    "        axes[i + 1].imshow(load_and_preprocess_image(img_path))\n",
    "        axes[i + 1].set_title(f\"Match {i+1}\")\n",
    "        axes[i + 1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Test with a new image\n",
    "test_image = \"../input/sample-clothing-images/test.jpg\"  # Replace with actual image path\n",
    "find_similar_images(test_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
